{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Educative-NLP.ipynb","provenance":[],"authorship_tag":"ABX9TyOSKbra8PmV3/LhPx+lYrFg"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"Gjd5AzPSK0eq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"5cb010c0-7877-4a94-92d7-56e1e06a7746","executionInfo":{"status":"ok","timestamp":1585483347403,"user_tz":-330,"elapsed":2961,"user":{"displayName":"Anshul Khare","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6XXwA6LjgCm-SvlTRUU6U7Lz4SjEdb_69ei5P=s64","userId":"16773804655187221706"}}},"source":["import tensorflow as tf\n","tokenizer = tf.keras.preprocessing.text.Tokenizer()\n","text_corpus = ['bob ate apples, and pears', 'fred ate apples!']\n","tokenizer.fit_on_texts(text_corpus)\n","new_texts = ['bob ate pears', 'fred ate pears']\n","print(tokenizer.texts_to_sequences(new_texts))\n","print(tokenizer.word_index)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["[[3, 1, 5], [6, 1, 5]]\n","{'ate': 1, 'apples': 2, 'bob': 3, 'and': 4, 'pears': 5, 'fred': 6}\n"],"name":"stdout"}]}]}